{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Network\n",
    "\n",
    "Attention is all you need\n",
    "- scale efficiently\n",
    "- parallel processes\n",
    "- attention to input meaning\n",
    "\n",
    "Large lanaguage models - foundation models\n",
    "(from more to less parameters)\n",
    "- GPT\n",
    "- BLOOM\n",
    "- FLAN-T5\n",
    "- PaLM\n",
    "- LLaMa\n",
    "- BERT\n",
    "\n",
    "The more parameters it stores, the more sophistacated tasks it can solve\n",
    "\n",
    "Prompt\n",
    "->\n",
    "Model (inference)\n",
    "->\n",
    "Completion\n",
    "\n",
    "LLM use cases\n",
    "- summarize\n",
    "- translation\n",
    "- translate to code\n",
    "- information retrivel (named entity recognition)\n",
    "- augment LLM by connect to external datasource or use them to invoke external API\n",
    "\n",
    "Before transformer:\n",
    "- RNN\n",
    "\n",
    "Transformer leaning:\n",
    "- learn relevance and context to every word in the sentence\n",
    "- attention weights to each word\n",
    "- attention map, to illustrate attention weight\n",
    "- self-attention\n",
    "\n",
    "Transformers:\n",
    "inputs -> tokenizer \n",
    "(token ID for complete word, or part of word)\n",
    "\n",
    "-> embedder\n",
    "\n",
    "-> encoder\n",
    "(encodes inputs/prompts with contextual understanding and produce one vector per input token)\n",
    "\n",
    "-> decoder\n",
    "(accepts input tokens and generate new token)\n",
    "\n",
    "\n",
    "encoder only model\n",
    "- same length input and output\n",
    "- performs well in classification tasks, like sentiment analysis\n",
    "- BERT\n",
    "\n",
    "encoder-decoder model\n",
    "- sequence model\n",
    "- text generation\n",
    "- BART, T5\n",
    "\n",
    "decoder only model\n",
    "- GPT, BLOOM, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Engineering\n",
    "\n",
    "In-context learning (ICL)\n",
    "- include examples or data\n",
    "- zero-shot inference\n",
    "- one-shot inference\n",
    "- few-shot inference\n",
    "\n",
    "Gen config\n",
    "- max new token\n",
    "- top-k sampling (k highest probability)\n",
    "- top-p sampling (top n total probability â‰¤ p)\n",
    "- temperature (higher e.g. > 1 - more random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gen AI Life Cycle\n",
    "\n",
    "### Scope\n",
    "define use case\n",
    "\n",
    "### Select\n",
    "choose an existing model, or pretrain your own\n",
    "\n",
    "### Adapt and align model\n",
    "- prompt engineering\n",
    "- fine-tuning (supervised learning)\n",
    "- align with human feedback\n",
    "- evaluation (metrics and benchmarks)\n",
    "\n",
    "### Application integration\n",
    "- optimize and deploy model\n",
    "- additional infrastrature\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gen_ai_learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
