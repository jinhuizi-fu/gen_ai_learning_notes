{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer Network\n",
    "\n",
    "Attention is all you need\n",
    "- scale efficiently\n",
    "- parallel processes\n",
    "- attention to input meaning\n",
    "\n",
    "Large lanaguage models - foundation models\n",
    "(from more to less parameters)\n",
    "- GPT\n",
    "- BLOOM\n",
    "- FLAN-T5\n",
    "- PaLM\n",
    "- LLaMa\n",
    "- BERT\n",
    "\n",
    "The more parameters it stors, the more sophistacated tasks it can solve\n",
    "\n",
    "Prompt\n",
    "->\n",
    "Model (inference)\n",
    "->\n",
    "Completion\n",
    "\n",
    "LLM use cases\n",
    "- summarize\n",
    "- translation\n",
    "- translate to code\n",
    "- information retrivel (named entity recognition)\n",
    "- augment LLM by connect to external datasource or use them to invoke external API\n",
    "\n",
    "Before transformer:\n",
    "- RNN\n",
    "\n",
    "Transformer leaning:\n",
    "- learn relevance and context to every word in the sentence\n",
    "- attention weights to each word\n",
    "- attention map, to illustrate attention weight\n",
    "- self-attention\n",
    "\n",
    "Transformers:\n",
    "inputs -> tokenizer \n",
    "(token ID for complete word, or part of word)\n",
    "\n",
    "-> embedder\n",
    "\n",
    "-> encoder\n",
    "(encodes inputs/prompts with contextual understanding and produce one vector per input token)\n",
    "\n",
    "-> decoder\n",
    "(accepts input tokens and generate new token)\n",
    "\n",
    "\n",
    "encoder only model\n",
    "- same length input and output\n",
    "- performs well in classification tasks, like sentiment analysis\n",
    "- BERT\n",
    "\n",
    "encoder-decoder model\n",
    "- sequence model\n",
    "- text generation\n",
    "- BART, T5\n",
    "\n",
    "decoder only model\n",
    "- GPT, BLOOM, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Engineering\n",
    "\n",
    "In-context learning (ICL)\n",
    "- include examples or data\n",
    "- zero-shot inference\n",
    "- one-shot inference\n",
    "- few-shot inference\n",
    "\n",
    "Gen config\n",
    "- max new token\n",
    "- top-k sampling (k highest probability)\n",
    "- top-p sampling (top n total probability ≤ p)\n",
    "- temperature (higher e.g. > 1 - more random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gen AI Life Cycle\n",
    "\n",
    "### Scope\n",
    "define use case\n",
    "\n",
    "### Select\n",
    "choose an existing model, or pretrain your own\n",
    "\n",
    "### Adapt and align model\n",
    "- prompt engineering\n",
    "- fine-tuning (supervised learning)\n",
    "- align with human feedback\n",
    "- evaluation (metrics and benchmarks)\n",
    "\n",
    "### Application integration\n",
    "- optimize and deploy model\n",
    "- additional infrastrature\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (4039999532.py, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [1]\u001b[0;36m\u001b[0m\n\u001b[0;31m    torchdata == 0.5.1 --quiet\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip\n",
    "%pip install --disable-pip-version-check \\\n",
    "    torch == 1.13.1 \\ \n",
    "    torchdata == 0.5.1 --quiet\n",
    "\n",
    "%pip install \\\n",
    "    transformers == 4.27.2\n",
    "    datasets == 2.11.0 --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: = not found\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --disable-pip-version-check torch == 1.13.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-4.41.1-py3-none-any.whl (9.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting regex!=2019.12.17\n",
      "  Downloading regex-2024.5.15-cp38-cp38-macosx_10_9_x86_64.whl (281 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m281.8/281.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting requests\n",
      "  Downloading requests-2.32.2-py3-none-any.whl (63 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.9/63.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tqdm>=4.27\n",
      "  Downloading tqdm-4.66.4-py3-none-any.whl (78 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.3/78.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting huggingface-hub<1.0,>=0.23.0\n",
      "  Downloading huggingface_hub-0.23.1-py3-none-any.whl (401 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m401.3/401.3 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting pyyaml>=5.1\n",
      "  Downloading PyYAML-6.0.1-cp38-cp38-macosx_10_9_x86_64.whl (191 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.7/191.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /Users/fujinhuizi/.local/share/virtualenvs/machine_learning_study_notes-EmPSjaem/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.14.0-py3-none-any.whl (12 kB)\n",
      "Collecting safetensors>=0.4.1\n",
      "  Downloading safetensors-0.4.3-cp38-cp38-macosx_10_12_x86_64.whl (416 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m416.3/416.3 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /Users/fujinhuizi/.local/share/virtualenvs/machine_learning_study_notes-EmPSjaem/lib/python3.8/site-packages (from transformers) (1.23.2)\n",
      "Collecting tokenizers<0.20,>=0.19\n",
      "  Downloading tokenizers-0.19.1-cp38-cp38-macosx_10_12_x86_64.whl (2.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting fsspec>=2023.5.0\n",
      "  Downloading fsspec-2024.5.0-py3-none-any.whl (316 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.1/316.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting typing-extensions>=3.7.4.3\n",
      "  Downloading typing_extensions-4.12.0-py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/fujinhuizi/.local/share/virtualenvs/machine_learning_study_notes-EmPSjaem/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Collecting urllib3<3,>=1.21.1\n",
      "  Downloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting idna<4,>=2.5\n",
      "  Downloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting certifi>=2017.4.17\n",
      "  Downloading certifi-2024.2.2-py3-none-any.whl (163 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/163.8 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting charset-normalizer<4,>=2\n",
      "  Downloading charset_normalizer-3.3.2-cp38-cp38-macosx_10_9_x86_64.whl (121 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: urllib3, typing-extensions, tqdm, safetensors, regex, pyyaml, idna, fsspec, filelock, charset-normalizer, certifi, requests, huggingface-hub, tokenizers, transformers\n",
      "Successfully installed certifi-2024.2.2 charset-normalizer-3.3.2 filelock-3.14.0 fsspec-2024.5.0 huggingface-hub-0.23.1 idna-3.7 pyyaml-6.0.1 regex-2024.5.15 requests-2.32.2 safetensors-0.4.3 tokenizers-0.19.1 tqdm-4.66.4 transformers-4.41.1 typing-extensions-4.12.0 urllib3-2.2.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.2.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /Users/fujinhuizi/.local/share/virtualenvs/machine_learning_study_notes-EmPSjaem/lib/python3.8/site-packages (22.2.2)\n",
      "Collecting pip\n",
      "  Using cached pip-24.0-py3-none-any.whl (2.1 MB)\n",
      "Installing collected packages: pip\n",
      "  Attempting uninstall: pip\n",
      "    Found existing installation: pip 22.2.2\n",
      "    Uninstalling pip-22.2.2:\n",
      "      Successfully uninstalled pip-22.2.2\n",
      "Successfully installed pip-24.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_env",
   "language": "python",
   "name": "ml_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
